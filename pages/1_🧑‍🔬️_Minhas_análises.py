import streamlit as st
import utils as db
import streamlit.components.v1 as components
from openai import OpenAI



PROMPT_INSIGHTS = '''VocÃª Ã© um especialista em conservaÃ§Ã£o da AmazÃ´nia, em especial da regiÃ£o no estado de Mato Grosso, Brasil.
Sua missÃ£o Ã© ajudar experts do IBAMA a identificar informaÃ§Ãµes de madeira extraÃ­da ilegalmente.

Cite 5 informaÃ§Ãµes que podem ser extraÃ­das da seguinte tabela que podem ser relevantes para detectar fraude na extraÃ§Ã£o de madeiras. 

DÃª alguns insights acionÃ¡veis para os experts.

Seja claro e direto.

Tabela: {}
'''

st.set_page_config(layout='wide')

st.title('ğŸ§‘â€ğŸ”¬ï¸ Minhas anÃ¡lises')
st.markdown('''
            Aqui vocÃª tem liberdade para fazer suas **prÃ³prias consultas SQL e anÃ¡lises**. Seus resultados sÃ£o analisados em tempo real pelo GPT-4.
            ''')
st.markdown('''---''')

col1, col2 = st.columns(spec=(1, 1), gap='medium')
db_tables = db.get_table_names()

col2.subheader('ğŸ—ƒ Tabelas disponÃ­veis no banco de dados')
tname = col2.selectbox('Selecione as tabelas que gostaria de visualizar', db_tables)
col2.markdown(f'Amostra da tabela **{tname}** selecionada:')
df = db.read_sql(f'''select * from "{tname}" limit 5;''')
col2.dataframe(df.head())

col1.subheader('ğŸ“Š FaÃ§a sua prÃ³pria consulta')
input_sql = col1.text_area('Entre com sua prÃ³pria consulta (Postgres SQL):', 
                            help='''Por exemplo: SELECT * FROM "<minha_tabela>" LIMIT 10;''', 
                            height=200)
if input_sql:
    user_df = db.read_sql(input_sql)
    col1.dataframe(user_df)

    if len(user_df) != 0:
        st.subheader('ğŸ’¡ Insights sobre dados suspeitos')
        with st.spinner('Nossa IA estÃ¡ analisando uma amostra dos seus dados...'):
            ans = db.gpt(prompt=PROMPT_INSIGHTS.format(user_df.head(100)))
            st.success(ans)

###########


st.subheader("ğŸ¤– Mais dÃºvidas? Converse com nossa IA!")

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4"

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Como posso ajudÃ¡-lo na sua anÃ¡lise?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        for response in client.chat.completions.create(
            model=st.session_state["openai_model"],
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            stream=True,
        ):
            full_response += (response.choices[0].delta.content or "")
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})